{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Clona el repositorio de YOLOv5\n",
    "# !git clone https://github.com/ultralytics/yolov5.git\n",
    "# %cd yolov5\n",
    "\n",
    "# # Instala las dependencias\n",
    "# !pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load YOLO Object Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mirvi/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-10-22 Python-3.9.7 torch-2.4.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n",
      "Using cache found in C:\\Users\\mirvi/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-10-22 Python-3.9.7 torch-2.4.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients, 4.5 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'ultralytics.models.yolo.model.YOLO'>\n"
     ]
    }
   ],
   "source": [
    "# Cargar el modelo YOLOv5\n",
    "model1 = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "model2 = torch.hub.load('ultralytics/yolov5', 'yolov5n', pretrained=True)\n",
    "model3 = YOLO('C:/Users/mirvi/Desktop/mii/UAB/4.1/PSIV2/detect mateicules/repte2_psiv2/object_tracking_yolo/yolov8n.pt')\n",
    "\n",
    "print(type(model3))\n",
    "\n",
    "# Definir clases de interés\n",
    "CLASSES_OF_INTEREST = ['car']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Tracker Class (per centroides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "class Tracker:\n",
    "    MAX_DISAPPEAR_LIMIT = 12\n",
    "    def __init__(self,res_p=1):\n",
    "        self.next_unique_id = 0\n",
    "        self.trackers = {}\n",
    "        self.disappear_trackers = {}\n",
    "        self.tracked_bboxes = {}\n",
    "        self.MAX_DISTANCE_THRESHOLD = 100*res_p\n",
    "    \n",
    "    \n",
    "    def init_object(self,centroid,boxes):\n",
    "        global next_unique_id\n",
    "        self.trackers[self.next_unique_id] = centroid\n",
    "        self.tracked_bboxes[self.next_unique_id] = boxes\n",
    "        self.disappear_trackers[self.next_unique_id] = 0\n",
    "        self.next_unique_id+=1\n",
    "\n",
    "    def del_object(self,track_id):\n",
    "        del self.trackers[track_id]\n",
    "        del self.tracked_bboxes[track_id]\n",
    "        del self.disappear_trackers[track_id]\n",
    "\n",
    "    def update_object(self,bboxes):\n",
    "        \n",
    "        if(len(bboxes)==0):\n",
    "            \n",
    "            for oid in list(self.disappear_trackers.keys()):\n",
    "                self.disappear_trackers[oid]+=1\n",
    "                \n",
    "                if self.disappear_trackers[oid] > Tracker.MAX_DISAPPEAR_LIMIT:\n",
    "                    self.del_object(oid)\n",
    "                \n",
    "            return self.tracked_bboxes\n",
    "        \n",
    "        else:   \n",
    "            input_centroids = np.zeros((len(bboxes),2)) \n",
    "            for i in range(len(bboxes)):\n",
    "                x,y,w,h = bboxes[i][0],bboxes[i][1],bboxes[i][2],bboxes[i][3]\n",
    "                cx,cy = x + w/2 , y + h/2\n",
    "                input_centroids[i] = (cx,cy)\n",
    "\n",
    "            \n",
    "            if(len(self.trackers)==0):\n",
    "                for i in range(len(input_centroids)):\n",
    "                    self.init_object(input_centroids[i],bboxes[i])\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                tracker_centroids = list(self.trackers.values())\n",
    "\n",
    "                distance_matrix = cdist(np.array(tracker_centroids) , input_centroids)\n",
    "\n",
    "                rows = distance_matrix.min(axis=1).argsort()\n",
    "                cols = distance_matrix.argmin(axis=1)[rows]\n",
    "\n",
    "                usedRows = set()\n",
    "                usedCols = set()\n",
    "                \n",
    "                tracker_ids = list(self.trackers.keys()) \n",
    "                for row,col in zip(rows,cols):\n",
    "                    if row in usedRows or col in usedCols:\n",
    "                        continue\n",
    "\n",
    "                    # Verifica si la distancia es menor que la distancia mínima\n",
    "                    if np.linalg.norm(tracker_centroids[row] - input_centroids[col]) > self.MAX_DISTANCE_THRESHOLD:\n",
    "                        continue  # Skip association if distance is greater than th pixels\n",
    "\n",
    "                    track_id = tracker_ids[row]\n",
    "                    \n",
    "                    self.trackers[track_id] = input_centroids[col]\n",
    "                    self.tracked_bboxes[track_id] = bboxes[col]\n",
    "\n",
    "                    self.disappear_trackers[track_id] = 0\n",
    "                    usedRows.add(row)                                \n",
    "                    usedCols.add(col)\n",
    "\n",
    "                unusedRows = set(range(0,distance_matrix.shape[0])).difference(usedRows)\n",
    "                unusedCols = set(range(0,distance_matrix.shape[1])).difference(usedCols)\n",
    "\n",
    "                if(distance_matrix.shape[0]>=distance_matrix.shape[1]):\n",
    "                    \n",
    "                    for r in unusedRows: \n",
    "                        track_id = tracker_ids[r]\n",
    "                        self.disappear_trackers[track_id]+=1\n",
    "                        if(self.disappear_trackers[track_id] > Tracker.MAX_DISAPPEAR_LIMIT):\n",
    "                            self.del_object(track_id)\n",
    "                else:\n",
    "                    for c in unusedCols:                    \n",
    "                        self.init_object(input_centroids[c],bboxes[c])\n",
    "\n",
    "        return self.tracked_bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize percent\n",
    "resize_percent = 0.7\n",
    "\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(\"/Users/mirvi/Desktop/mii/UAB/4.1/PSIV2/detect mateicules/repte2_psiv2/data_r2/long_uab_flow.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Object Detection and Tracking over video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656\n"
     ]
    }
   ],
   "source": [
    "# PROCESS VIDEO IN GRAYSCALE\n",
    "gray_video_og = []\n",
    "\n",
    "i=0\n",
    "# Configura para comenzar desde el frame 300\n",
    "start_frame = 45000\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "while True:\n",
    "    ret, fr = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # resize frame\n",
    "    fr = cv2.resize(fr, (0, 0), fx=resize_percent, fy=resize_percent)\n",
    "\n",
    "    # # to gray\n",
    "    # fr2 = cv2.cvtColor(fr1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # # apply clahe contrast\n",
    "    # clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    # fr = clahe.apply(fr2)\n",
    "\n",
    "    # agafar nomes frames que volem\n",
    "    if i>0:\n",
    "        gray_video_og.append(fr)\n",
    "    if i == 10000:\n",
    "        break\n",
    "    i+=1\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 5 cars, 134.6ms\n",
      "Speed: 11.0ms preprocess, 134.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 0\n",
      "\n",
      "0: 640x384 6 cars, 165.6ms\n",
      "Speed: 13.0ms preprocess, 165.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 7\n",
      "\n",
      "0: 640x384 6 cars, 127.7ms\n",
      "Speed: 4.0ms preprocess, 127.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 14\n",
      "\n",
      "0: 640x384 5 cars, 122.7ms\n",
      "Speed: 4.0ms preprocess, 122.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 21\n",
      "\n",
      "0: 640x384 5 cars, 120.7ms\n",
      "Speed: 4.0ms preprocess, 120.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 28\n",
      "\n",
      "0: 640x384 5 cars, 119.7ms\n",
      "Speed: 4.0ms preprocess, 119.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 35\n",
      "\n",
      "0: 640x384 5 cars, 121.7ms\n",
      "Speed: 4.0ms preprocess, 121.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 42\n",
      "\n",
      "0: 640x384 5 cars, 219.4ms\n",
      "Speed: 4.0ms preprocess, 219.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 49\n",
      "\n",
      "0: 640x384 5 cars, 118.7ms\n",
      "Speed: 4.0ms preprocess, 118.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 56\n",
      "\n",
      "0: 640x384 5 cars, 117.7ms\n",
      "Speed: 4.0ms preprocess, 117.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 63\n",
      "\n",
      "0: 640x384 5 cars, 125.7ms\n",
      "Speed: 4.0ms preprocess, 125.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 70\n",
      "\n",
      "0: 640x384 5 cars, 121.7ms\n",
      "Speed: 4.0ms preprocess, 121.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 77\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 118.7ms\n",
      "Speed: 4.0ms preprocess, 118.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 84\n",
      "\n",
      "0: 640x384 6 cars, 118.7ms\n",
      "Speed: 4.0ms preprocess, 118.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 91\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 125.7ms\n",
      "Speed: 5.0ms preprocess, 125.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 98\n",
      "\n",
      "0: 640x384 6 cars, 120.7ms\n",
      "Speed: 4.0ms preprocess, 120.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 105\n",
      "\n",
      "0: 640x384 7 cars, 120.7ms\n",
      "Speed: 4.0ms preprocess, 120.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 112\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 truck, 122.7ms\n",
      "Speed: 4.0ms preprocess, 122.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 119\n",
      "\n",
      "0: 640x384 1 bicycle, 6 cars, 1 truck, 120.7ms\n",
      "Speed: 4.0ms preprocess, 120.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 126\n",
      "\n",
      "0: 640x384 1 bicycle, 6 cars, 1 truck, 128.7ms\n",
      "Speed: 4.0ms preprocess, 128.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 133\n",
      "\n",
      "0: 640x384 1 person, 1 bicycle, 6 cars, 119.7ms\n",
      "Speed: 4.0ms preprocess, 119.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 140\n",
      "\n",
      "0: 640x384 1 bicycle, 6 cars, 114.7ms\n",
      "Speed: 5.0ms preprocess, 114.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 147\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 118.7ms\n",
      "Speed: 4.0ms preprocess, 118.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 154\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 123.7ms\n",
      "Speed: 4.0ms preprocess, 123.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 161\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 126.7ms\n",
      "Speed: 4.0ms preprocess, 126.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 168\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 130.7ms\n",
      "Speed: 4.0ms preprocess, 130.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 175\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 119.7ms\n",
      "Speed: 5.0ms preprocess, 119.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 182\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 214.4ms\n",
      "Speed: 4.0ms preprocess, 214.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 189\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 121.7ms\n",
      "Speed: 4.0ms preprocess, 121.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 196\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 124.7ms\n",
      "Speed: 4.0ms preprocess, 124.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 203\n",
      "\n",
      "0: 640x384 1 person, 1 bicycle, 6 cars, 116.7ms\n",
      "Speed: 4.0ms preprocess, 116.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 210\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 117.7ms\n",
      "Speed: 4.0ms preprocess, 117.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 217\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 122.7ms\n",
      "Speed: 3.0ms preprocess, 122.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 224\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 118.7ms\n",
      "Speed: 4.0ms preprocess, 118.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 231\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 116.7ms\n",
      "Speed: 4.0ms preprocess, 116.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 238\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 114.7ms\n",
      "Speed: 4.0ms preprocess, 114.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 245\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 118.7ms\n",
      "Speed: 5.0ms preprocess, 118.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 252\n",
      "\n",
      "0: 640x384 1 person, 1 bicycle, 6 cars, 115.7ms\n",
      "Speed: 4.0ms preprocess, 115.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 259\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 123.7ms\n",
      "Speed: 4.0ms preprocess, 123.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 266\n",
      "\n",
      "0: 640x384 1 person, 1 bicycle, 6 cars, 124.7ms\n",
      "Speed: 4.0ms preprocess, 124.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 273\n",
      "\n",
      "0: 640x384 1 person, 2 bicycles, 6 cars, 122.7ms\n",
      "Speed: 5.0ms preprocess, 122.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 280\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 125.7ms\n",
      "Speed: 6.0ms preprocess, 125.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 287\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 121.7ms\n",
      "Speed: 4.0ms preprocess, 121.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 294\n",
      "\n",
      "0: 640x384 1 person, 2 bicycles, 5 cars, 118.7ms\n",
      "Speed: 3.0ms preprocess, 118.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 301\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 117.7ms\n",
      "Speed: 4.0ms preprocess, 117.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 308\n",
      "\n",
      "0: 640x384 1 person, 1 bicycle, 6 cars, 117.7ms\n",
      "Speed: 5.0ms preprocess, 117.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 315\n",
      "\n",
      "0: 640x384 1 person, 1 bicycle, 6 cars, 222.4ms\n",
      "Speed: 4.0ms preprocess, 222.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 322\n",
      "\n",
      "0: 640x384 1 person, 2 bicycles, 5 cars, 119.7ms\n",
      "Speed: 4.0ms preprocess, 119.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 329\n",
      "\n",
      "0: 640x384 1 person, 2 bicycles, 6 cars, 145.6ms\n",
      "Speed: 3.0ms preprocess, 145.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 336\n",
      "\n",
      "0: 640x384 1 person, 1 bicycle, 6 cars, 113.7ms\n",
      "Speed: 4.0ms preprocess, 113.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 343\n",
      "\n",
      "0: 640x384 1 person, 1 bicycle, 6 cars, 116.7ms\n",
      "Speed: 4.0ms preprocess, 116.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 350\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 120.7ms\n",
      "Speed: 4.0ms preprocess, 120.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 357\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 128.7ms\n",
      "Speed: 4.0ms preprocess, 128.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 364\n",
      "\n",
      "0: 640x384 6 cars, 116.7ms\n",
      "Speed: 5.0ms preprocess, 116.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 371\n",
      "\n",
      "0: 640x384 6 cars, 116.7ms\n",
      "Speed: 4.0ms preprocess, 116.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 378\n",
      "\n",
      "0: 640x384 6 cars, 119.7ms\n",
      "Speed: 4.0ms preprocess, 119.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 385\n",
      "\n",
      "0: 640x384 7 cars, 118.7ms\n",
      "Speed: 4.0ms preprocess, 118.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 392\n",
      "\n",
      "0: 640x384 7 cars, 117.7ms\n",
      "Speed: 4.0ms preprocess, 117.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 399\n",
      "\n",
      "0: 640x384 7 cars, 122.7ms\n",
      "Speed: 4.0ms preprocess, 122.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 406\n",
      "\n",
      "0: 640x384 7 cars, 114.7ms\n",
      "Speed: 4.0ms preprocess, 114.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 413\n",
      "\n",
      "0: 640x384 7 cars, 120.7ms\n",
      "Speed: 4.0ms preprocess, 120.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 420\n",
      "\n",
      "0: 640x384 6 cars, 118.7ms\n",
      "Speed: 4.0ms preprocess, 118.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 427\n",
      "\n",
      "0: 640x384 6 cars, 185.5ms\n",
      "Speed: 26.9ms preprocess, 185.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 434\n",
      "\n",
      "0: 640x384 6 cars, 126.7ms\n",
      "Speed: 4.0ms preprocess, 126.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 441\n",
      "\n",
      "0: 640x384 7 cars, 127.7ms\n",
      "Speed: 5.0ms preprocess, 127.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 448\n",
      "\n",
      "0: 640x384 7 cars, 115.7ms\n",
      "Speed: 4.0ms preprocess, 115.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 455\n",
      "\n",
      "0: 640x384 6 cars, 117.7ms\n",
      "Speed: 6.0ms preprocess, 117.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 462\n",
      "\n",
      "0: 640x384 7 cars, 127.7ms\n",
      "Speed: 3.0ms preprocess, 127.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 469\n",
      "\n",
      "0: 640x384 7 cars, 119.7ms\n",
      "Speed: 6.0ms preprocess, 119.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 476\n",
      "\n",
      "0: 640x384 8 cars, 117.7ms\n",
      "Speed: 4.0ms preprocess, 117.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 483\n",
      "\n",
      "0: 640x384 6 cars, 121.7ms\n",
      "Speed: 4.0ms preprocess, 121.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 490\n",
      "\n",
      "0: 640x384 6 cars, 117.7ms\n",
      "Speed: 5.0ms preprocess, 117.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 497\n",
      "\n",
      "0: 640x384 6 cars, 124.7ms\n",
      "Speed: 4.0ms preprocess, 124.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 504\n",
      "\n",
      "0: 640x384 5 cars, 123.7ms\n",
      "Speed: 4.0ms preprocess, 123.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 511\n",
      "\n",
      "0: 640x384 6 cars, 117.7ms\n",
      "Speed: 4.0ms preprocess, 117.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 518\n",
      "\n",
      "0: 640x384 6 cars, 119.7ms\n",
      "Speed: 5.0ms preprocess, 119.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 525\n",
      "\n",
      "0: 640x384 5 cars, 118.7ms\n",
      "Speed: 4.0ms preprocess, 118.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 532\n",
      "\n",
      "0: 640x384 6 cars, 115.7ms\n",
      "Speed: 4.0ms preprocess, 115.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 539\n",
      "\n",
      "0: 640x384 5 cars, 117.7ms\n",
      "Speed: 4.0ms preprocess, 117.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 546\n",
      "\n",
      "0: 640x384 5 cars, 119.7ms\n",
      "Speed: 4.0ms preprocess, 119.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 553\n",
      "\n",
      "0: 640x384 5 cars, 219.4ms\n",
      "Speed: 4.0ms preprocess, 219.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 560\n",
      "\n",
      "0: 640x384 5 cars, 115.7ms\n",
      "Speed: 4.0ms preprocess, 115.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 567\n",
      "\n",
      "0: 640x384 5 cars, 122.7ms\n",
      "Speed: 4.0ms preprocess, 122.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 574\n",
      "\n",
      "0: 640x384 5 cars, 123.7ms\n",
      "Speed: 4.0ms preprocess, 123.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 581\n",
      "\n",
      "0: 640x384 5 cars, 127.7ms\n",
      "Speed: 3.0ms preprocess, 127.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 588\n",
      "\n",
      "0: 640x384 5 cars, 118.7ms\n",
      "Speed: 4.0ms preprocess, 118.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 595\n",
      "\n",
      "0: 640x384 5 cars, 114.7ms\n",
      "Speed: 4.0ms preprocess, 114.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 602\n",
      "\n",
      "0: 640x384 4 cars, 125.7ms\n",
      "Speed: 4.0ms preprocess, 125.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 609\n",
      "\n",
      "0: 640x384 4 cars, 124.7ms\n",
      "Speed: 4.0ms preprocess, 124.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 616\n",
      "\n",
      "0: 640x384 4 cars, 125.7ms\n",
      "Speed: 6.0ms preprocess, 125.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 623\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 122.7ms\n",
      "Speed: 3.0ms preprocess, 122.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 630\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 118.7ms\n",
      "Speed: 5.0ms preprocess, 118.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 637\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 117.7ms\n",
      "Speed: 4.0ms preprocess, 117.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 644\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 115.7ms\n",
      "Speed: 4.0ms preprocess, 115.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "frame id: 651\n",
      "count up: 2\n",
      "count down: 0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "\n",
    "time_start_all = time.time()\n",
    "\n",
    "# Define selected model\n",
    "model = model3\n",
    "\n",
    "# Init tracker\n",
    "tracker2 = Tracker(res_p=resize_percent)\n",
    "\n",
    "# Define ROI dimensions\n",
    "\n",
    "roix1 = int(150 * resize_percent)\n",
    "roix2 = int(480 * resize_percent)\n",
    "roiy1 = int(340 * resize_percent)\n",
    "roiy2 = int(900 * resize_percent)\n",
    "\n",
    "# Define reference line in the middle of the ROI\n",
    "line_y_position = ((roiy2 - roiy1) // 2) - int(40 * resize_percent)\n",
    "\n",
    "# Counters for cars moving up and down\n",
    "count_up = 0\n",
    "count_down = 0\n",
    "tmp_count_down = 0\n",
    "tmp_count_up = 0\n",
    "\n",
    "# Dictionary to store previous positions of each car\n",
    "previous_positions = {}\n",
    "\n",
    "# Dictionary to track crossed status\n",
    "crossed_up = {id: False for id in range(200)}\n",
    "crossed_down = {id: False for id in range(200)}\n",
    "parked = {id: False for id in range(200)}\n",
    "prev_in_bottom = {id: False for id in range(200)}\n",
    "\n",
    "current_frame_id = []\n",
    "previous_frame_id = []\n",
    "\n",
    "# Distance threshold for movement in pixels\n",
    "movement_threshold = 50*resize_percent\n",
    "\n",
    "# Initialize last positions dictionary\n",
    "last_positions = {}\n",
    "\n",
    "frame_id = 0\n",
    "\n",
    "# init box_id var\n",
    "box_id = 0\n",
    "\n",
    "# right roi margin\n",
    "right_margin = 15*resize_percent\n",
    "bottom_margin = 10*resize_percent\n",
    "\n",
    "\n",
    "\n",
    "while frame_id < len(gray_video_og) - 1:\n",
    "    # Start time measurement\n",
    "    time_start = time.time()\n",
    "\n",
    "    # Process the frame\n",
    "    fr = gray_video_og[frame_id]\n",
    "    frame = fr.copy()\n",
    "    height, width, _ = frame.shape\n",
    "\n",
    "    # Extract ROI\n",
    "    roi = frame[roiy1:roiy2, roix1:roix2]\n",
    "\n",
    "    # 1. Object Detection\n",
    "    ts_od = time.time()\n",
    "    results = model(roi)\n",
    "\n",
    "    # Filter detections based on size and movement\n",
    "    detections = []\n",
    "    for idx,det in enumerate(results[0].boxes):\n",
    "        x1, y1, x2, y2, conf, cls = det.data[0]\n",
    "        if cls == 2:\n",
    "            w = int(x2 - x1)\n",
    "            h = int(y2 - y1)\n",
    "            x = int(x1)\n",
    "            y = int(y1)\n",
    "\n",
    "            # Only keep detections with a certain size\n",
    "            if w > 50 * resize_percent and h > 50 * resize_percent:\n",
    "                detections.append([x, y, w, h])\n",
    "\n",
    "    te_od = time.time()\n",
    "\n",
    "    # Draw text and ROI with reference line\n",
    "    cv2.putText(frame, f'ObjDet time: {(te_od - ts_od):.2f}', \n",
    "                (int(10 * resize_percent), int(30 * resize_percent)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"UP: {count_up}\", (int(10 * resize_percent), int(700 * resize_percent)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "    cv2.putText(frame, f\"DOWN: {count_down}\", (int(10 * resize_percent), int(750 * resize_percent)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.rectangle(frame, (roix1, roiy1), (roix2, roiy2), (0, 255, 125), 2)\n",
    "\n",
    "    # Draw line with increments\n",
    "    line_inc = [-100, 0, 20]\n",
    "    for inc in line_inc:\n",
    "        cv2.line(roi, (0, line_y_position + inc), (width, line_y_position + inc), (0, 255, 255), 2)\n",
    "\n",
    "    # 2. Object Tracking\n",
    "    boxes_ids = tracker2.update_object(detections)\n",
    "\n",
    "    # Draw bounding boxes and text for tracked objects\n",
    "    for box_id, box in boxes_ids.items():\n",
    "        x, y, w, h = box\n",
    "        id = box_id\n",
    "\n",
    "        # add to current frame id\n",
    "        current_frame_id.append(id)\n",
    "\n",
    "        # check if car is parked\n",
    "        if x + w + roix1 > roix2 - right_margin:\n",
    "            parked[id] = True\n",
    "\n",
    "        # Draw ID and bounding box\n",
    "        if parked[id]:\n",
    "            cv2.putText(roi, f\"PARKED {str(id)}\", (x, y - 10), cv2.FONT_HERSHEY_PLAIN, 0.7, (255, 127, 0), 1)\n",
    "            cv2.rectangle(roi, (x, y), (x + w, y + h), (200, 0, 255), 2)\n",
    "        else:\n",
    "            cv2.putText(roi, str(id), (x, y - 10), cv2.FONT_HERSHEY_PLAIN, 0.7, (255, 127, 0), 1)\n",
    "            cv2.rectangle(roi, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Check if the car crossed the line\n",
    "        current_y = y + h // 2\n",
    "        if id not in previous_positions:\n",
    "            previous_positions[id] = current_y\n",
    "            continue\n",
    "\n",
    "        previous_y = previous_positions[id]\n",
    "\n",
    "        # Check if parked is no more parked and going down\n",
    "        if parked[id] and x + w + roix1 < roix2 - right_margin:\n",
    "                # chek each line\n",
    "                for inc in line_inc:\n",
    "                    # Check crossing of reference line down\n",
    "                    if previous_y < line_y_position + int(inc * resize_percent) and current_y > line_y_position + int(inc * resize_percent) and not crossed_down[id]:\n",
    "                        tmp_count_down += 1\n",
    "                        # cv2.putText(frame, f\"DOWN: {count_down}\", (int(10 * resize_percent), int(750 * resize_percent)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 2)\n",
    "                        crossed_down[id] = True\n",
    "                        parked[id] = False\n",
    "                        break\n",
    "\n",
    "        # Check if non-parked car crossed the line\n",
    "        elif not crossed_up[id] and not crossed_down[id] and not parked[id]:\n",
    "\n",
    "            for inc in line_inc:\n",
    "                # Check crossing of reference line\n",
    "                if previous_y < line_y_position + int(inc * resize_percent) and current_y > line_y_position + int(inc * resize_percent) and not crossed_down[id]:\n",
    "                    tmp_count_down += 1\n",
    "                    # cv2.putText(frame, f\"DOWN: {count_down}\", (int(10 * resize_percent), int(750 * resize_percent)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 2)\n",
    "                    crossed_down[id] = True\n",
    "                    break\n",
    "                elif previous_y > line_y_position + int(inc * resize_percent) and current_y < line_y_position + int(inc * resize_percent) and not crossed_up[id]:\n",
    "                    tmp_count_up += 1\n",
    "                    # cv2.putText(frame, f\"UP: {count_up}\", (int(10 * resize_percent), int(750 * resize_percent)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                    crossed_up[id] = True\n",
    "                    break\n",
    "\n",
    "        # Update the car's previous position\n",
    "        previous_positions[id] = current_y\n",
    "\n",
    "    # Check if any car has left\n",
    "    for id in previous_frame_id:\n",
    "        if id not in current_frame_id:\n",
    "            \n",
    "            # update counters if car not parked\n",
    "            if not parked[id] or (parked[id] and crossed_up[id]):\n",
    "                if crossed_down[id]:\n",
    "                    count_down += 1\n",
    "                elif crossed_up[id]:\n",
    "                    count_up += 1\n",
    "        \n",
    "\n",
    "    # Update previous frame id\n",
    "    previous_frame_id = current_frame_id.copy()\n",
    "    current_frame_id = []\n",
    "\n",
    "    # Calculate FPS\n",
    "    time_end = time.time()\n",
    "    time_per_frame = time_end - time_start\n",
    "    fps = 1 / time_per_frame if time_per_frame > 0 else 0\n",
    "    cv2.putText(frame, f'Processing time: {fps:.2f} FPS', (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "\n",
    "    # Show frames\n",
    "    cv2.imshow(\"roi\", roi)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    print('frame id:', frame_id)\n",
    "    # Advance frame\n",
    "    frame_id += 7\n",
    "\n",
    "    # Exit with ESC key\n",
    "    if cv2.waitKey(30) == 27:\n",
    "        break\n",
    "\n",
    "time_end_all = time.time()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print('count up:', count_up)\n",
    "print('count down:', count_down)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CALCUL TEMPS FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 414.15 seconds\n",
      "Total frames: 12609\n",
      "FPS: 30.45\n"
     ]
    }
   ],
   "source": [
    "final_time = time_end_all - time_start_all\n",
    "total_frames = len(gray_video_og)\n",
    "\n",
    "print(f\"Total time: {final_time:.2f} seconds\")\n",
    "print(f\"Total frames: {total_frames}\")\n",
    "print(f\"FPS: {total_frames / final_time:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 'n'\n",
    "if not p:\n",
    "    print('si')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
